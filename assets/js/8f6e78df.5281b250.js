"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[7033],{8068(e,n,r){r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-4/chapter-4-visual-slam","title":"Chapter 4: Visual SLAM","description":"Chapter Goal","source":"@site/docs/module-4/chapter-4-visual-slam.md","sourceDirName":"module-4","slug":"/module-4/chapter-4-visual-slam","permalink":"/Master-Robotics-AI/textbook/module-4/chapter-4-visual-slam","draft":false,"unlisted":false,"editUrl":"https://github.com/HasnainCodeHub/Master-Robotics-AI/tree/main/docs/docs/module-4/chapter-4-visual-slam.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"chapter-4-visual-slam","title":"Chapter 4: Visual SLAM","sidebar_label":"4. Visual SLAM","sidebar_position":5},"sidebar":"textbookSidebar","previous":{"title":"3. Isaac ROS","permalink":"/Master-Robotics-AI/textbook/module-4/chapter-3-isaac-ros-integration"},"next":{"title":"5. Domain Randomization","permalink":"/Master-Robotics-AI/textbook/module-4/chapter-5-domain-randomization"}}');var s=r(4848),t=r(8453);const a={id:"chapter-4-visual-slam",title:"Chapter 4: Visual SLAM",sidebar_label:"4. Visual SLAM",sidebar_position:5},l="Chapter 4: Visual SLAM with Isaac ROS",o={},d=[{value:"Chapter Goal",id:"chapter-goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Why Visual SLAM?",id:"why-visual-slam",level:2},{value:"The Localization Problem",id:"the-localization-problem",level:3},{value:"Visual SLAM Pipeline",id:"visual-slam-pipeline",level:3},{value:"Visual Odometry Fundamentals",id:"visual-odometry",level:2},{value:"Feature Detection",id:"feature-detection",level:3},{value:"Feature Matching",id:"feature-matching",level:3},{value:"Motion Estimation",id:"motion-estimation",level:3},{value:"SLAM vs Odometry",id:"slam-vs-odom",level:2},{value:"The Drift Problem",id:"the-drift-problem",level:3},{value:"Loop Closure Solution",id:"loop-closure-solution",level:3},{value:"Isaac ROS VSLAM Configuration",id:"isaac-vslam",level:2},{value:"Package Overview",id:"package-overview",level:3},{value:"Launch Configuration",id:"launch-configuration",level:3},{value:"Key Parameters",id:"key-parameters",level:3},{value:"Environment Tuning",id:"tuning",level:2},{value:"Indoor Warehouse",id:"indoor-warehouse",level:3},{value:"Outdoor Environment",id:"outdoor-environment",level:3},{value:"Dynamic Environment",id:"dynamic-environment",level:3},{value:"Accuracy Evaluation",id:"evaluation",level:2},{value:"Metrics",id:"metrics",level:3},{value:"Evaluation with Ground Truth",id:"evaluation-with-ground-truth",level:3},{value:"Expected Performance",id:"expected-performance",level:3},{value:"Navigation Integration",id:"nav-integration",level:2},{value:"Using VSLAM Odometry with Nav2",id:"using-vslam-odometry-with-nav2",level:3},{value:"TF Tree Configuration",id:"tf-tree-configuration",level:3},{value:"Failure Modes and Recovery",id:"failures",level:2},{value:"Common Failures",id:"common-failures",level:3},{value:"Safe Behavior on Failure",id:"safe-behavior-on-failure",level:3},{value:"Summary",id:"summary",level:2},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-4-visual-slam-with-isaac-ros",children:"Chapter 4: Visual SLAM with Isaac ROS"})}),"\n",(0,s.jsx)(n.h2,{id:"chapter-goal",children:"Chapter Goal"}),"\n",(0,s.jsxs)(n.p,{children:["By the end of this chapter, you will be able to ",(0,s.jsx)(n.strong,{children:"implement Visual SLAM using Isaac ROS packages"})," for robust robot localization, understanding the algorithms, configuration, and evaluation methodology."]}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"ID"}),(0,s.jsx)(n.th,{children:"Objective"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4.1"}),(0,s.jsx)(n.td,{children:"Explain Visual SLAM concepts: feature tracking, bundle adjustment, loop closure"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4.2"}),(0,s.jsx)(n.td,{children:"Configure Isaac ROS Visual SLAM for stereo cameras"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4.3"}),(0,s.jsx)(n.td,{children:"Tune VSLAM parameters for different environments"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4.4"}),(0,s.jsx)(n.td,{children:"Evaluate VSLAM accuracy using ground truth comparison"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4.5"}),(0,s.jsx)(n.td,{children:"Integrate VSLAM with ROS 2 navigation stack"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"why-visual-slam",children:"Why Visual SLAM?"}),"\n",(0,s.jsx)(n.h3,{id:"the-localization-problem",children:"The Localization Problem"}),"\n",(0,s.jsx)(n.p,{children:"Robots need to know where they are. Traditional approaches:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Method"}),(0,s.jsx)(n.th,{children:"Sensors"}),(0,s.jsx)(n.th,{children:"Limitations"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Wheel odometry"}),(0,s.jsx)(n.td,{children:"Encoders"}),(0,s.jsx)(n.td,{children:"Drift, slip"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"GPS"}),(0,s.jsx)(n.td,{children:"Receiver"}),(0,s.jsx)(n.td,{children:"Indoor failure"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Beacon-based"}),(0,s.jsx)(n.td,{children:"Infrastructure"}),(0,s.jsx)(n.td,{children:"Requires setup"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"LiDAR SLAM"}),(0,s.jsx)(n.td,{children:"LiDAR"}),(0,s.jsx)(n.td,{children:"Expensive sensor"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Visual SLAM"})}),(0,s.jsx)(n.td,{children:"Camera"}),(0,s.jsx)(n.td,{children:"Works anywhere with texture"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"Visual SLAM uses cameras\u2014already present on most robots\u2014for localization and mapping."}),"\n",(0,s.jsx)(n.h3,{id:"visual-slam-pipeline",children:"Visual SLAM Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                    Visual SLAM Pipeline                          \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502  Stereo Cameras \u2500\u2500\u25ba Feature Detection \u2500\u2500\u25ba Feature Matching      \u2502\r\n\u2502       \u2502                    \u2502                    \u2502                \u2502\r\n\u2502       \u2514\u2500\u2500 Left/Right      \u2514\u2500\u2500 ORB, FAST       \u2514\u2500\u2500 Between frames\u2502\r\n\u2502           images              features                           \u2502\r\n\u2502                                                                  \u2502\r\n\u2502  \u2500\u2500\u25ba Motion Estimation \u2500\u2500\u25ba Local Optimization \u2500\u2500\u25ba Loop Closure  \u2502\r\n\u2502            \u2502                      \u2502                    \u2502         \u2502\r\n\u2502            \u2514\u2500\u2500 Frame-to-frame    \u2514\u2500\u2500 Bundle           \u2514\u2500\u2500 Detect \u2502\r\n\u2502                odometry              adjustment            revisit\u2502\r\n\u2502                                                                  \u2502\r\n\u2502  \u2500\u2500\u25ba Map \u2500\u2500\u25ba Pose Output                                        \u2502\r\n\u2502        \u2502          \u2502                                              \u2502\r\n\u2502        \u2514\u2500\u2500 3D    \u2514\u2500\u2500 Transform to /odom or /map frame           \u2502\r\n\u2502            points                                                \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"visual-odometry",children:"Visual Odometry Fundamentals"}),"\n",(0,s.jsx)(n.h3,{id:"feature-detection",children:"Feature Detection"}),"\n",(0,s.jsx)(n.p,{children:"The first step: find distinctive points in images."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Image \u2500\u2500\u25ba Feature Detector \u2500\u2500\u25ba Keypoints + Descriptors\r\n               \u2502\r\n               \u2514\u2500\u2500 ORB, FAST, SIFT, SURF\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"ORB Features"})," (used by Isaac ROS VSLAM):"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Fast to compute"}),"\n",(0,s.jsx)(n.li,{children:"Rotation invariant"}),"\n",(0,s.jsx)(n.li,{children:"Scale invariant"}),"\n",(0,s.jsx)(n.li,{children:"Binary descriptors (efficient matching)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"feature-matching",children:"Feature Matching"}),"\n",(0,s.jsx)(n.p,{children:"Match features between consecutive frames:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Frame t \u2500\u2500\u2510                    \u250c\u2500\u2500 Matched Features\r\n          \u251c\u2500\u2500 Feature Matcher \u2500\u2500\u2524\r\nFrame t+1 \u2518                    \u2514\u2500\u2500 Outlier Rejection\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Physical Grounding"}),": Feature matching fails when:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Motion blur (fast movement)"}),"\n",(0,s.jsx)(n.li,{children:"Low texture (blank walls)"}),"\n",(0,s.jsx)(n.li,{children:"Lighting changes"}),"\n",(0,s.jsx)(n.li,{children:"Dynamic objects"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"motion-estimation",children:"Motion Estimation"}),"\n",(0,s.jsx)(n.p,{children:"From matched features, estimate camera motion:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Matched Features \u2500\u2500\u25ba Essential Matrix \u2500\u2500\u25ba Rotation + Translation\r\n                          \u2502\r\n                          \u2514\u2500\u2500 5-point algorithm + RANSAC\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Result"}),": Relative pose change between frames (visual odometry)."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"slam-vs-odom",children:"SLAM vs Odometry"}),"\n",(0,s.jsx)(n.h3,{id:"the-drift-problem",children:"The Drift Problem"}),"\n",(0,s.jsx)(n.p,{children:"Visual odometry accumulates error:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"True path:    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\r\nVO estimate:  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\r\n                      \u2514\u2500\u2500 Small errors accumulate\r\n                          to large drift\n"})}),"\n",(0,s.jsx)(n.p,{children:"After 100m of travel, drift might be 1-5m."}),"\n",(0,s.jsx)(n.h3,{id:"loop-closure-solution",children:"Loop Closure Solution"}),"\n",(0,s.jsx)(n.p,{children:"SLAM detects when the robot revisits a location:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                                          \u2502\r\n\u2502    Start \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\r\n\u2502      \u2502                        \u2502          \u2502\r\n\u2502      \u2502     Loop Closure!      \u2502          \u2502\r\n\u2502      \u2502     \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\r\n\u2502      \u2502                                   \u2502\r\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n\u2502                                          \u2502\r\n\u2502  Loop closure corrects accumulated drift \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.p,{children:"When loop closure is detected, the entire trajectory is optimized to be consistent."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"isaac-vslam",children:"Isaac ROS VSLAM Configuration"}),"\n",(0,s.jsx)(n.h3,{id:"package-overview",children:"Package Overview"}),"\n",(0,s.jsx)(n.p,{children:"Isaac ROS VSLAM provides GPU-accelerated visual SLAM:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"CUDA-accelerated feature extraction"}),"\n",(0,s.jsx)(n.li,{children:"GPU-based feature matching"}),"\n",(0,s.jsx)(n.li,{children:"Efficient pose graph optimization"}),"\n",(0,s.jsx)(n.li,{children:"Stereo camera support"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"launch-configuration",children:"Launch Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# launch/isaac_vslam.launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch_ros.actions import ComposableNodeContainer\r\nfrom launch_ros.descriptions import ComposableNode\r\n\r\ndef generate_launch_description():\r\n    return LaunchDescription([\r\n        ComposableNodeContainer(\r\n            name='vslam_container',\r\n            namespace='',\r\n            package='rclcpp_components',\r\n            executable='component_container_mt',\r\n            composable_node_descriptions=[\r\n                ComposableNode(\r\n                    package='isaac_ros_visual_slam',\r\n                    plugin='nvidia::isaac_ros::visual_slam::VisualSlamNode',\r\n                    name='visual_slam',\r\n                    parameters=[{\r\n                        # Camera configuration\r\n                        'num_cameras': 2,\r\n                        'enable_rectified_pose': True,\r\n                        'enable_localization_n_mapping': True,\r\n\r\n                        # Feature detection\r\n                        'enable_imu_fusion': False,  # True if IMU available\r\n                        'gyro_noise_density': 0.00087,  # From M1 specs\r\n                        'accel_noise_density': 0.039,\r\n\r\n                        # Performance tuning\r\n                        'image_jitter_threshold_ms': 34.0,\r\n                        'enable_slam_visualization': True,\r\n\r\n                        # Output frames\r\n                        'map_frame': 'map',\r\n                        'odom_frame': 'odom',\r\n                        'base_frame': 'base_link',\r\n                    }],\r\n                    remappings=[\r\n                        ('stereo_camera/left/image', '/camera/left/image_raw'),\r\n                        ('stereo_camera/left/camera_info', '/camera/left/camera_info'),\r\n                        ('stereo_camera/right/image', '/camera/right/image_raw'),\r\n                        ('stereo_camera/right/camera_info', '/camera/right/camera_info'),\r\n                        ('visual_slam/tracking/odometry', '/odom'),\r\n                        ('visual_slam/vis/landmarks_cloud', '/vslam/landmarks'),\r\n                    ]\r\n                ),\r\n            ],\r\n            output='screen',\r\n        ),\r\n    ])\n"})}),"\n",(0,s.jsx)(n.h3,{id:"key-parameters",children:"Key Parameters"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Typical Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"num_cameras"})}),(0,s.jsx)(n.td,{children:"Stereo (2) or mono (1)"}),(0,s.jsx)(n.td,{children:"2"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"enable_imu_fusion"})}),(0,s.jsx)(n.td,{children:"Fuse IMU data"}),(0,s.jsx)(n.td,{children:"True if available"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"image_jitter_threshold_ms"})}),(0,s.jsx)(n.td,{children:"Max frame timing jitter"}),(0,s.jsx)(n.td,{children:"34 (for 30fps)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"map_frame"})}),(0,s.jsx)(n.td,{children:"SLAM map frame name"}),(0,s.jsx)(n.td,{children:'"map"'})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"enable_localization_n_mapping"})}),(0,s.jsx)(n.td,{children:"Full SLAM vs VO only"}),(0,s.jsx)(n.td,{children:"True"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"tuning",children:"Environment Tuning"}),"\n",(0,s.jsx)(n.h3,{id:"indoor-warehouse",children:"Indoor Warehouse"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Well-textured indoor environment\r\nindoor_params = {\r\n    'enable_localization_n_mapping': True,\r\n    'enable_slam_visualization': True,\r\n    'path_max_size': 1000,\r\n    'image_jitter_threshold_ms': 34.0,\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"outdoor-environment",children:"Outdoor Environment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Variable lighting, larger scale\r\noutdoor_params = {\r\n    'enable_localization_n_mapping': True,\r\n    'enable_slam_visualization': False,  # Save compute\r\n    'path_max_size': 5000,  # Longer paths\r\n    'image_jitter_threshold_ms': 50.0,  # More tolerance\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"dynamic-environment",children:"Dynamic Environment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Moving objects present\r\ndynamic_params = {\r\n    'enable_localization_n_mapping': True,\r\n    # More aggressive outlier rejection\r\n    # (Configure in feature matching)\r\n}\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"evaluation",children:"Accuracy Evaluation"}),"\n",(0,s.jsx)(n.h3,{id:"metrics",children:"Metrics"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"ATE (Absolute Trajectory Error)"}),": Global accuracy"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"ATE = sqrt(mean(||p_estimated - p_ground_truth||\xb2))\r\n\r\np = position at each timestamp\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"RPE (Relative Pose Error)"}),": Local accuracy"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"RPE = error between consecutive pose transformations\r\n      Better for odometry evaluation\n"})}),"\n",(0,s.jsx)(n.h3,{id:"evaluation-with-ground-truth",children:"Evaluation with Ground Truth"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"Evaluate VSLAM accuracy against ground truth.\"\"\"\r\n\r\nimport numpy as np\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom nav_msgs.msg import Odometry\r\nfrom geometry_msgs.msg import PoseStamped\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass VSLAMEvaluator(Node):\r\n    def __init__(self):\r\n        super().__init__('vslam_evaluator')\r\n\r\n        self.vslam_poses = []\r\n        self.gt_poses = []\r\n\r\n        # Subscribe to VSLAM odometry\r\n        self.vslam_sub = self.create_subscription(\r\n            Odometry,\r\n            '/odom',  # VSLAM output\r\n            self.vslam_callback,\r\n            10\r\n        )\r\n\r\n        # Subscribe to ground truth (from Isaac Sim)\r\n        self.gt_sub = self.create_subscription(\r\n            PoseStamped,\r\n            '/ground_truth/pose',\r\n            self.gt_callback,\r\n            10\r\n        )\r\n\r\n        self.timer = self.create_timer(5.0, self.compute_metrics)\r\n\r\n    def vslam_callback(self, msg):\r\n        pose = [\r\n            msg.pose.pose.position.x,\r\n            msg.pose.pose.position.y,\r\n            msg.pose.pose.position.z\r\n        ]\r\n        self.vslam_poses.append(pose)\r\n\r\n    def gt_callback(self, msg):\r\n        pose = [\r\n            msg.pose.position.x,\r\n            msg.pose.position.y,\r\n            msg.pose.position.z\r\n        ]\r\n        self.gt_poses.append(pose)\r\n\r\n    def compute_metrics(self):\r\n        if len(self.vslam_poses) < 10 or len(self.gt_poses) < 10:\r\n            return\r\n\r\n        vslam = np.array(self.vslam_poses)\r\n        gt = np.array(self.gt_poses)\r\n\r\n        # Align lengths (simple approach)\r\n        min_len = min(len(vslam), len(gt))\r\n        vslam = vslam[:min_len]\r\n        gt = gt[:min_len]\r\n\r\n        # Compute ATE\r\n        errors = np.linalg.norm(vslam - gt, axis=1)\r\n        ate = np.sqrt(np.mean(errors**2))\r\n\r\n        # Compute drift (error at end vs start)\r\n        drift = errors[-1] - errors[0]\r\n\r\n        # Compute RPE (simplified)\r\n        vslam_deltas = np.diff(vslam, axis=0)\r\n        gt_deltas = np.diff(gt, axis=0)\r\n        rpe = np.sqrt(np.mean(np.linalg.norm(vslam_deltas - gt_deltas, axis=1)**2))\r\n\r\n        self.get_logger().info(f'ATE: {ate:.4f}m')\r\n        self.get_logger().info(f'Drift: {drift:.4f}m')\r\n        self.get_logger().info(f'RPE: {rpe:.4f}m')\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = VSLAMEvaluator()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,s.jsx)(n.h3,{id:"expected-performance",children:"Expected Performance"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Environment"}),(0,s.jsx)(n.th,{children:"ATE (m)"}),(0,s.jsx)(n.th,{children:"Drift (%/m)"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Indoor, textured"}),(0,s.jsx)(n.td,{children:"0.05-0.1"}),(0,s.jsx)(n.td,{children:"0.5-1%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Indoor, low texture"}),(0,s.jsx)(n.td,{children:"0.1-0.3"}),(0,s.jsx)(n.td,{children:"1-3%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Outdoor, structured"}),(0,s.jsx)(n.td,{children:"0.1-0.2"}),(0,s.jsx)(n.td,{children:"1-2%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Outdoor, unstructured"}),(0,s.jsx)(n.td,{children:"0.2-0.5"}),(0,s.jsx)(n.td,{children:"2-5%"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"nav-integration",children:"Navigation Integration"}),"\n",(0,s.jsx)(n.h3,{id:"using-vslam-odometry-with-nav2",children:"Using VSLAM Odometry with Nav2"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# launch/navigation_with_vslam.launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\nfrom launch.actions import IncludeLaunchDescription\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\n\r\ndef generate_launch_description():\r\n    return LaunchDescription([\r\n        # Isaac ROS VSLAM\r\n        IncludeLaunchDescription(\r\n            PythonLaunchDescriptionSource('isaac_vslam.launch.py')\r\n        ),\r\n\r\n        # Nav2 with VSLAM odometry\r\n        Node(\r\n            package='nav2_bringup',\r\n            executable='navigation_launch.py',\r\n            parameters=[{\r\n                'odom_topic': '/odom',  # From VSLAM\r\n                'use_sim_time': True,\r\n            }],\r\n        ),\r\n    ])\n"})}),"\n",(0,s.jsx)(n.h3,{id:"tf-tree-configuration",children:"TF Tree Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"map \u2500\u2500\u25ba odom \u2500\u2500\u25ba base_link \u2500\u2500\u25ba sensors\r\n \u2502        \u2502\r\n \u2502        \u2514\u2500\u2500 VSLAM provides map\u2192odom transform\r\n \u2502\r\n \u2514\u2500\u2500 VSLAM provides initial map frame\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"failures",children:"Failure Modes and Recovery"}),"\n",(0,s.jsx)(n.h3,{id:"common-failures",children:"Common Failures"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Failure Mode"}),(0,s.jsx)(n.th,{children:"Cause"}),(0,s.jsx)(n.th,{children:"Detection"}),(0,s.jsx)(n.th,{children:"Recovery"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Tracking loss"}),(0,s.jsx)(n.td,{children:"Fast motion, blur"}),(0,s.jsx)(n.td,{children:"High RPE"}),(0,s.jsx)(n.td,{children:"Slow down, re-initialize"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Drift"}),(0,s.jsx)(n.td,{children:"Low texture"}),(0,s.jsx)(n.td,{children:"ATE divergence"}),(0,s.jsx)(n.td,{children:"Loop closure, IMU fusion"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Scale drift"}),(0,s.jsx)(n.td,{children:"Monocular only"}),(0,s.jsx)(n.td,{children:"GT comparison"}),(0,s.jsx)(n.td,{children:"Use stereo, wheel odometry"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Map corruption"}),(0,s.jsx)(n.td,{children:"Dynamic objects"}),(0,s.jsx)(n.td,{children:"Inconsistent landmarks"}),(0,s.jsx)(n.td,{children:"Map reset"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"safe-behavior-on-failure",children:"Safe Behavior on Failure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class SafeVSLAMNode(Node):\r\n    def __init__(self):\r\n        super().__init__('safe_vslam')\r\n\r\n        self.tracking_lost = False\r\n        self.last_pose_time = None\r\n\r\n    def vslam_callback(self, msg):\r\n        current_time = self.get_clock().now()\r\n\r\n        # Check for tracking timeout\r\n        if self.last_pose_time is not None:\r\n            dt = (current_time - self.last_pose_time).nanoseconds / 1e9\r\n            if dt > 0.5:  # No update for 0.5s\r\n                self.tracking_lost = True\r\n                self.get_logger().warn('VSLAM tracking lost!')\r\n                self.safe_stop()\r\n\r\n        self.last_pose_time = current_time\r\n\r\n    def safe_stop(self):\r\n        # Publish zero velocity\r\n        # Alert navigation system\r\n        pass\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"This chapter covered Visual SLAM with Isaac ROS:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Visual odometry"})," extracts motion from feature matches between frames."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SLAM"})," adds loop closure to correct accumulated drift, providing globally consistent localization."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS VSLAM"})," provides GPU-accelerated stereo SLAM with configurable parameters."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Environment tuning"})," adapts parameters for indoor, outdoor, and dynamic scenarios."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Accuracy evaluation"})," uses ATE and RPE metrics compared to ground truth."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Navigation integration"})," connects VSLAM odometry to Nav2 for autonomous navigation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Drift vs Loop Closure"}),": After 100m of travel without revisiting locations, your VSLAM shows 2m ATE. Is this a problem? What would help?"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Feature Failure"}),": Your robot enters a hallway with blank walls. VSLAM tracking fails. What sensor could help? How?"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Parameter Tuning"}),": Your indoor warehouse has fluorescent lighting that flickers at 60Hz. Camera is at 30fps. What timing-related problems might occur?"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Accuracy Evaluation"}),": Isaac Sim provides perfect ground truth. Real hardware doesn't. How would you evaluate VSLAM accuracy on real hardware?"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Navigation Integration"}),": VSLAM provides map\u2192odom transform. Nav2 needs odom\u2192base_link too. Where does this come from?"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,s.jsxs)(n.p,{children:["In ",(0,s.jsx)(n.a,{href:"/module-4/chapter-5-domain-randomization",children:"Chapter 5: Domain Randomization"}),", you'll use Isaac Replicator to train robust perception systems that transfer from simulation to reality."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>a,x:()=>l});var i=r(6540);const s={},t=i.createContext(s);function a(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);