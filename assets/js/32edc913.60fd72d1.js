"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2543],{1907(n,e,r){r.r(e),r.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-5/chapter-2-llm-task-planning","title":"Chapter 2: LLM Task Planning","description":"Chapter Goal","source":"@site/docs/module-5/chapter-2-llm-task-planning.md","sourceDirName":"module-5","slug":"/module-5/chapter-2-llm-task-planning","permalink":"/Master-Robotics-AI/textbook/module-5/chapter-2-llm-task-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/HasnainCodeHub/Master-Robotics-AI/tree/main/docs/docs/module-5/chapter-2-llm-task-planning.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"chapter-2-llm-task-planning","title":"Chapter 2: LLM Task Planning","sidebar_label":"2. LLM Task Planning","sidebar_position":3},"sidebar":"textbookSidebar","previous":{"title":"1. Speech Recognition","permalink":"/Master-Robotics-AI/textbook/module-5/chapter-1-speech-recognition"},"next":{"title":"3. Grounding","permalink":"/Master-Robotics-AI/textbook/module-5/chapter-3-grounding"}}');var s=r(4848),a=r(8453);const i={id:"chapter-2-llm-task-planning",title:"Chapter 2: LLM Task Planning",sidebar_label:"2. LLM Task Planning",sidebar_position:3},l="Chapter 2: LLM-Based Task Planning",o={},d=[{value:"Chapter Goal",id:"chapter-goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"LLMs for Task Planning: Strengths and Limitations",id:"llms-for-task-planning-strengths-and-limitations",level:2},{value:"What LLMs Do Well",id:"what-llms-do-well",level:3},{value:"What LLMs Do Poorly",id:"what-llms-do-poorly",level:3},{value:"Structured Output Design",id:"structured-output",level:2},{value:"Task Plan Schema",id:"task-plan-schema",level:3},{value:"Valid Action Types",id:"valid-action-types",level:3},{value:"Prompt Engineering",id:"prompt-engineering",level:2},{value:"System Prompt",id:"system-prompt",level:3},{value:"Few-Shot Examples",id:"few-shot-examples",level:3},{value:"LLM Integration",id:"llm-integration",level:2},{value:"Task Planner Node",id:"task-planner-node",level:3},{value:"Output Validation",id:"validation",level:2},{value:"Schema Validation with Pydantic",id:"schema-validation-with-pydantic",level:3},{value:"Handling Invalid Responses",id:"handling-invalid-responses",level:3},{value:"Caching Strategy",id:"caching",level:2},{value:"Semantic Caching",id:"semantic-caching",level:3},{value:"Summary",id:"summary",level:2},{value:"Safety Callout",id:"safety-callout",level:2},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-2-llm-based-task-planning",children:"Chapter 2: LLM-Based Task Planning"})}),"\n",(0,s.jsx)(e.h2,{id:"chapter-goal",children:"Chapter Goal"}),"\n",(0,s.jsxs)(e.p,{children:["By the end of this chapter, you will be able to ",(0,s.jsx)(e.strong,{children:"design LLM prompts that translate natural language commands into structured robot task plans"}),", with emphasis on prompt engineering discipline, structured outputs, and understanding LLM limitations."]}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"ID"}),(0,s.jsx)(e.th,{children:"Objective"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.1"}),(0,s.jsx)(e.td,{children:"Explain LLM strengths and limitations for robot task planning"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.2"}),(0,s.jsx)(e.td,{children:"Design prompts producing structured task plans with explicit schemas"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.3"}),(0,s.jsx)(e.td,{children:"Implement few-shot prompting with task decomposition examples"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.4"}),(0,s.jsx)(e.td,{children:"Validate LLM outputs against schema"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.5"}),(0,s.jsx)(e.td,{children:"Implement caching for repeated commands"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"2.6"}),(0,s.jsx)(e.td,{children:"Design prompts including robot capability constraints"})]})]})]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"llms-for-task-planning-strengths-and-limitations",children:"LLMs for Task Planning: Strengths and Limitations"}),"\n",(0,s.jsx)(e.h3,{id:"what-llms-do-well",children:"What LLMs Do Well"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Capability"}),(0,s.jsx)(e.th,{children:"Example"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Semantic understanding"}),(0,s.jsx)(e.td,{children:'"grab the thing next to the keyboard" \u2192 object reference'})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Command decomposition"}),(0,s.jsx)(e.td,{children:'"clean the table" \u2192 [pick up items, wipe surface, return items]'})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Context handling"}),(0,s.jsx)(e.td,{children:'Remembering "it" refers to previous object'})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Variation handling"}),(0,s.jsx)(e.td,{children:'"pick up", "grab", "get" \u2192 same action'})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"what-llms-do-poorly",children:"What LLMs Do Poorly"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Limitation"}),(0,s.jsx)(e.th,{children:"Example Failure"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Physical reasoning"})}),(0,s.jsx)(e.td,{children:"Plans path through solid wall"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Spatial awareness"})}),(0,s.jsx)(e.td,{children:'"Move left" without knowing robot orientation'})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Constraint satisfaction"})}),(0,s.jsx)(e.td,{children:"Commands exceed joint limits"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Hallucination"})}),(0,s.jsx)(e.td,{children:"Invents objects not in scene"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Consistency"})}),(0,s.jsx)(e.td,{children:"Different plans for identical commands"})]})]})]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Critical Insight"}),": LLMs are semantic parsers, not physical reasoners. Physical constraints must be explicit in prompts and validated after generation."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"structured-output",children:"Structured Output Design"}),"\n",(0,s.jsx)(e.h3,{id:"task-plan-schema",children:"Task Plan Schema"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-json",children:'{\r\n  "command_id": "string",\r\n  "original_text": "string",\r\n  "actions": [\r\n    {\r\n      "action_type": "string",\r\n      "target": "string | null",\r\n      "parameters": {\r\n        "position": [x, y, z] | null,\r\n        "orientation": [x, y, z, w] | null,\r\n        "speed": "number | null",\r\n        "force": "number | null"\r\n      },\r\n      "preconditions": ["string"],\r\n      "effects": ["string"]\r\n    }\r\n  ],\r\n  "success_criteria": "string",\r\n  "abort_conditions": ["string"]\r\n}\n'})}),"\n",(0,s.jsx)(e.h3,{id:"valid-action-types",children:"Valid Action Types"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'VALID_ACTIONS = {\r\n    "navigate_to": {\r\n        "required_params": ["position"],\r\n        "optional_params": ["speed", "orientation"]\r\n    },\r\n    "pick": {\r\n        "required_params": ["target"],\r\n        "optional_params": ["approach_direction"]\r\n    },\r\n    "place": {\r\n        "required_params": ["position"],\r\n        "optional_params": ["orientation"]\r\n    },\r\n    "open_gripper": {\r\n        "required_params": [],\r\n        "optional_params": []\r\n    },\r\n    "close_gripper": {\r\n        "required_params": [],\r\n        "optional_params": ["force"]\r\n    },\r\n    "wait": {\r\n        "required_params": ["duration"],\r\n        "optional_params": []\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"prompt-engineering",children:"Prompt Engineering"}),"\n",(0,s.jsx)(e.h3,{id:"system-prompt",children:"System Prompt"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'SYSTEM_PROMPT = """You are a robot task planner. Convert natural language commands into structured action plans.\r\n\r\nROBOT CAPABILITIES:\r\n- Navigate to positions within workspace (0,0,0) to (5,5,2) meters\r\n- Maximum speed: 0.5 m/s\r\n- Pick objects up to 2 kg\r\n- Gripper opening: 0-10 cm\r\n- Cannot climb stairs or open doors\r\n\r\nAVAILABLE ACTIONS:\r\n- navigate_to(position): Move base to position\r\n- pick(target): Grasp target object\r\n- place(position): Release held object at position\r\n- open_gripper(): Open gripper fully\r\n- close_gripper(force): Close gripper with specified force\r\n- wait(duration): Wait for specified seconds\r\n\r\nOUTPUT FORMAT:\r\nRespond ONLY with valid JSON matching this schema:\r\n{\r\n  "actions": [\r\n    {\r\n      "action_type": "string",\r\n      "target": "string or null",\r\n      "parameters": {},\r\n      "preconditions": [],\r\n      "effects": []\r\n    }\r\n  ]\r\n}\r\n\r\nCONSTRAINTS:\r\n- All positions must be within workspace bounds\r\n- Never exceed maximum speed\r\n- Never attempt to pick objects heavier than 2 kg\r\n- If command is ambiguous, include "clarification_needed" field\r\n- If command is impossible, return empty actions with "error" field\r\n"""\n'})}),"\n",(0,s.jsx)(e.h3,{id:"few-shot-examples",children:"Few-Shot Examples"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'FEW_SHOT_EXAMPLES = [\r\n    {\r\n        "user": "Pick up the red mug",\r\n        "assistant": """{\r\n  "actions": [\r\n    {\r\n      "action_type": "navigate_to",\r\n      "target": null,\r\n      "parameters": {"position": "NEAR_red_mug"},\r\n      "preconditions": ["red_mug_visible", "path_clear"],\r\n      "effects": ["robot_near_red_mug"]\r\n    },\r\n    {\r\n      "action_type": "open_gripper",\r\n      "target": null,\r\n      "parameters": {},\r\n      "preconditions": ["robot_near_red_mug"],\r\n      "effects": ["gripper_open"]\r\n    },\r\n    {\r\n      "action_type": "pick",\r\n      "target": "red_mug",\r\n      "parameters": {},\r\n      "preconditions": ["gripper_open", "red_mug_reachable"],\r\n      "effects": ["holding_red_mug"]\r\n    }\r\n  ],\r\n  "success_criteria": "holding_red_mug"\r\n}"""\r\n    },\r\n    {\r\n        "user": "Put the mug on the shelf",\r\n        "assistant": """{\r\n  "actions": [\r\n    {\r\n      "action_type": "navigate_to",\r\n      "target": null,\r\n      "parameters": {"position": "NEAR_shelf"},\r\n      "preconditions": ["holding_object", "path_clear"],\r\n      "effects": ["robot_near_shelf"]\r\n    },\r\n    {\r\n      "action_type": "place",\r\n      "target": null,\r\n      "parameters": {"position": "ON_shelf"},\r\n      "preconditions": ["robot_near_shelf", "shelf_has_space"],\r\n      "effects": ["object_on_shelf"]\r\n    },\r\n    {\r\n      "action_type": "open_gripper",\r\n      "target": null,\r\n      "parameters": {},\r\n      "preconditions": ["object_on_shelf"],\r\n      "effects": ["gripper_empty"]\r\n    }\r\n  ],\r\n  "success_criteria": "object_on_shelf AND gripper_empty"\r\n}"""\r\n    },\r\n    {\r\n        "user": "Move at 10 m/s to the door",\r\n        "assistant": """{\r\n  "actions": [],\r\n  "error": "Requested speed (10 m/s) exceeds maximum (0.5 m/s)",\r\n  "suggestion": "Command with speed <= 0.5 m/s"\r\n}"""\r\n    }\r\n]\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"llm-integration",children:"LLM Integration"}),"\n",(0,s.jsx)(e.h3,{id:"task-planner-node",children:"Task Planner Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""LLM-based task planning node."""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nimport json\r\nfrom openai import OpenAI\r\n\r\n\r\nclass TaskPlannerNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'task_planner\')\r\n\r\n        # LLM client (OpenAI, local, or other)\r\n        self.client = OpenAI()\r\n\r\n        # Schema for validation\r\n        self.action_schema = self.load_schema()\r\n\r\n        # Cache for repeated commands\r\n        self.plan_cache = {}\r\n\r\n        # Subscribers and publishers\r\n        self.text_sub = self.create_subscription(\r\n            String, \'/speech/text\', self.text_callback, 10\r\n        )\r\n        self.plan_pub = self.create_publisher(\r\n            String, \'/task_planner/plan\', 10\r\n        )\r\n\r\n        self.get_logger().info(\'Task planner ready\')\r\n\r\n    def text_callback(self, msg: String):\r\n        """Process transcribed speech command."""\r\n        command = msg.data.strip()\r\n\r\n        # Check cache first\r\n        if command in self.plan_cache:\r\n            self.get_logger().info(f\'Using cached plan for: "{command}"\')\r\n            plan = self.plan_cache[command]\r\n        else:\r\n            # Generate new plan\r\n            plan = self.generate_plan(command)\r\n\r\n            # Validate\r\n            if self.validate_plan(plan):\r\n                self.plan_cache[command] = plan\r\n            else:\r\n                self.get_logger().error(\'Generated plan failed validation\')\r\n                return\r\n\r\n        # Publish\r\n        plan_msg = String()\r\n        plan_msg.data = json.dumps(plan)\r\n        self.plan_pub.publish(plan_msg)\r\n\r\n    def generate_plan(self, command: str) -> dict:\r\n        """Generate task plan using LLM."""\r\n        import time\r\n        start = time.time()\r\n\r\n        messages = [\r\n            {"role": "system", "content": SYSTEM_PROMPT}\r\n        ]\r\n\r\n        # Add few-shot examples\r\n        for example in FEW_SHOT_EXAMPLES:\r\n            messages.append({"role": "user", "content": example["user"]})\r\n            messages.append({"role": "assistant", "content": example["assistant"]})\r\n\r\n        # Add current command\r\n        messages.append({"role": "user", "content": command})\r\n\r\n        response = self.client.chat.completions.create(\r\n            model="gpt-4",  # Or local model\r\n            messages=messages,\r\n            temperature=0,  # Deterministic\r\n            response_format={"type": "json_object"}\r\n        )\r\n\r\n        latency = (time.time() - start) * 1000\r\n        self.get_logger().info(f\'LLM inference: {latency:.0f}ms\')\r\n\r\n        try:\r\n            plan = json.loads(response.choices[0].message.content)\r\n            plan[\'original_command\'] = command\r\n            plan[\'inference_latency_ms\'] = latency\r\n            return plan\r\n        except json.JSONDecodeError:\r\n            return {"error": "Failed to parse LLM response", "actions": []}\r\n\r\n    def validate_plan(self, plan: dict) -> bool:\r\n        """Validate plan against schema and constraints."""\r\n        if "error" in plan:\r\n            return True  # Error responses are valid\r\n\r\n        if "actions" not in plan:\r\n            self.get_logger().error(\'Plan missing "actions" field\')\r\n            return False\r\n\r\n        for action in plan["actions"]:\r\n            # Check action type\r\n            if action.get("action_type") not in VALID_ACTIONS:\r\n                self.get_logger().error(\r\n                    f\'Invalid action type: {action.get("action_type")}\'\r\n                )\r\n                return False\r\n\r\n            # Check required parameters\r\n            action_spec = VALID_ACTIONS[action["action_type"]]\r\n            params = action.get("parameters", {})\r\n            for req_param in action_spec["required_params"]:\r\n                if req_param not in params and action.get("target") is None:\r\n                    self.get_logger().error(\r\n                        f\'Missing required param: {req_param}\'\r\n                    )\r\n                    return False\r\n\r\n        return True\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"validation",children:"Output Validation"}),"\n",(0,s.jsx)(e.h3,{id:"schema-validation-with-pydantic",children:"Schema Validation with Pydantic"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from pydantic import BaseModel, validator\r\nfrom typing import List, Optional, Dict, Any\r\n\r\nclass ActionParameters(BaseModel):\r\n    position: Optional[List[float]] = None\r\n    orientation: Optional[List[float]] = None\r\n    speed: Optional[float] = None\r\n    force: Optional[float] = None\r\n\r\n    @validator('position')\r\n    def validate_position(cls, v):\r\n        if v is not None and isinstance(v, list) and len(v) == 3:\r\n            x, y, z = v\r\n            if not (0 <= x <= 5 and 0 <= y <= 5 and 0 <= z <= 2):\r\n                raise ValueError('Position outside workspace')\r\n        return v\r\n\r\n    @validator('speed')\r\n    def validate_speed(cls, v):\r\n        if v is not None and v > 0.5:\r\n            raise ValueError(f'Speed {v} exceeds maximum 0.5 m/s')\r\n        return v\r\n\r\nclass Action(BaseModel):\r\n    action_type: str\r\n    target: Optional[str] = None\r\n    parameters: ActionParameters = ActionParameters()\r\n    preconditions: List[str] = []\r\n    effects: List[str] = []\r\n\r\nclass TaskPlan(BaseModel):\r\n    actions: List[Action]\r\n    success_criteria: Optional[str] = None\r\n    abort_conditions: List[str] = []\r\n    error: Optional[str] = None\r\n    clarification_needed: Optional[str] = None\r\n\r\ndef validate_task_plan(plan_dict: dict) -> TaskPlan:\r\n    \"\"\"Validate and parse task plan.\"\"\"\r\n    return TaskPlan(**plan_dict)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"handling-invalid-responses",children:"Handling Invalid Responses"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def safe_generate_plan(self, command: str, max_retries: int = 2) -> dict:\r\n    """Generate plan with retry on validation failure."""\r\n    for attempt in range(max_retries + 1):\r\n        plan = self.generate_plan(command)\r\n\r\n        try:\r\n            validated = validate_task_plan(plan)\r\n            return validated.dict()\r\n        except Exception as e:\r\n            self.get_logger().warn(\r\n                f\'Validation failed (attempt {attempt + 1}): {e}\'\r\n            )\r\n\r\n            if attempt < max_retries:\r\n                # Regenerate with error feedback\r\n                continue\r\n\r\n    return {"error": "Failed to generate valid plan", "actions": []}\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"caching",children:"Caching Strategy"}),"\n",(0,s.jsx)(e.h3,{id:"semantic-caching",children:"Semantic Caching"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from sentence_transformers import SentenceTransformer\r\nimport numpy as np\r\n\r\nclass SemanticCache:\r\n    def __init__(self, threshold: float = 0.95):\r\n        self.encoder = SentenceTransformer(\'all-MiniLM-L6-v2\')\r\n        self.cache = {}  # embedding -> plan\r\n        self.embeddings = []\r\n        self.threshold = threshold\r\n\r\n    def get(self, command: str) -> Optional[dict]:\r\n        """Get cached plan for semantically similar command."""\r\n        embedding = self.encoder.encode(command)\r\n\r\n        for i, cached_emb in enumerate(self.embeddings):\r\n            similarity = np.dot(embedding, cached_emb) / (\r\n                np.linalg.norm(embedding) * np.linalg.norm(cached_emb)\r\n            )\r\n            if similarity > self.threshold:\r\n                return list(self.cache.values())[i]\r\n\r\n        return None\r\n\r\n    def put(self, command: str, plan: dict):\r\n        """Cache plan with command embedding."""\r\n        embedding = self.encoder.encode(command)\r\n        self.embeddings.append(embedding)\r\n        self.cache[command] = plan\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"This chapter covered LLM-based task planning:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"LLM strengths"}),": Semantic understanding, command decomposition, variation handling."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"LLM limitations"}),": No physical reasoning, hallucination, inconsistency\u2014constraints must be explicit."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Structured outputs"})," with JSON schemas enable downstream validation."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Prompt engineering"})," includes capability constraints, few-shot examples, and output format."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Validation"})," rejects invalid plans before execution."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Caching"})," reduces latency for repeated commands."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"safety-callout",children:"Safety Callout"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"LLMs can generate dangerous commands:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'"Move at maximum speed through the warehouse"'}),"\n",(0,s.jsx)(e.li,{children:'"Pick up the 50 kg crate"'}),"\n",(0,s.jsx)(e.li,{children:'"Navigate through the glass door"'}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"The safety filter (Chapter 5) is the final defense, but prompts should include constraints to reduce dangerous outputs."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Limitation Awareness"}),": An LLM plans a path that goes through a wall. Why did this happen? How would you prevent it?"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Schema Design"}),": Design an action schema for a robot that can also open doors. What new action types and parameters?"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Few-Shot Design"}),': Write a few-shot example for handling an impossible command: "Fly to the ceiling"']}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Validation"}),": Your validator accepts all plans because it only checks action types. What additional validations are critical?"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Caching Trade-off"}),': "Pick up the red mug" and "Pick up the blue mug" are semantically similar. Should they share a cache entry? Why or why not?']}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,s.jsxs)(e.p,{children:["In ",(0,s.jsx)(e.a,{href:"/module-5/chapter-3-grounding",children:"Chapter 3: Grounding"}),", you'll implement the layer that maps these symbolic task plans to executable ROS 2 actions with real-world verification."]})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},8453(n,e,r){r.d(e,{R:()=>i,x:()=>l});var t=r(6540);const s={},a=t.createContext(s);function i(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);