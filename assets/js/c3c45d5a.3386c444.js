"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[6529],{6826(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"module-1/chapter-4-physical-constraints","title":"Chapter 4: Physical Constraints and the Perception-Action Loop","description":"Chapter Goal","source":"@site/docs/module-1/chapter-4-physical-constraints.md","sourceDirName":"module-1","slug":"/module-1/chapter-4-physical-constraints","permalink":"/Master-Robotics-AI/textbook/module-1/chapter-4-physical-constraints","draft":false,"unlisted":false,"editUrl":"https://github.com/HasnainCodeHub/Master-Robotics-AI/tree/main/docs/docs/module-1/chapter-4-physical-constraints.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"chapter-4-physical-constraints","title":"Chapter 4: Physical Constraints and the Perception-Action Loop","sidebar_label":"4. Physical Constraints","sidebar_position":5},"sidebar":"textbookSidebar","previous":{"title":"3. Actuator Fundamentals","permalink":"/Master-Robotics-AI/textbook/module-1/chapter-3-actuator-fundamentals"},"next":{"title":"Overview","permalink":"/Master-Robotics-AI/textbook/module-2/"}}');var i=s(4848),r=s(8453);const l={id:"chapter-4-physical-constraints",title:"Chapter 4: Physical Constraints and the Perception-Action Loop",sidebar_label:"4. Physical Constraints",sidebar_position:5},a="Chapter 4: Physical Constraints and the Perception-Action Loop",c={},o=[{value:"Chapter Goal",id:"chapter-goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"The Problem: When Components Work but Systems Fail",id:"the-problem-when-components-work-but-systems-fail",level:2},{value:"The Complete Perception-Action Loop",id:"complete-loop",level:2},{value:"Loop Components",id:"loop-components",level:3},{value:"Latency Budget",id:"latency-budget",level:3},{value:"Why Latency Matters",id:"why-latency-matters",level:3},{value:"Latency Budget Analysis",id:"latency-analysis",level:2},{value:"Example: Ball-Catching Robot",id:"example-ball-catching-robot",level:3},{value:"What If We Used Standard Components?",id:"what-if-we-used-standard-components",level:3},{value:"Uncertainty Propagation",id:"uncertainty-propagation",level:2},{value:"Sources of Uncertainty",id:"sources-of-uncertainty",level:3},{value:"Propagation Example",id:"propagation-example",level:3},{value:"Reducing Uncertainty",id:"reducing-uncertainty",level:3},{value:"Real-Time Requirements",id:"realtime-requirements",level:2},{value:"Hard Real-Time",id:"hard-real-time",level:3},{value:"Soft Real-Time",id:"soft-real-time",level:3},{value:"Best-Effort",id:"best-effort",level:3},{value:"Classifying System Components",id:"classifying-system-components",level:3},{value:"Physical Constraints Specification",id:"constraints-spec",level:2},{value:"Specification Template",id:"specification-template",level:3},{value:"Example: Pick and Place Coffee Cup",id:"example-pick-and-place-coffee-cup",level:3},{value:"Case Study: Analyzing a Complete System",id:"case-study",level:2},{value:"System Components",id:"system-components",level:3},{value:"Perception-Action Loop",id:"perception-action-loop",level:3},{value:"Timing Analysis",id:"timing-analysis",level:3},{value:"Uncertainty Analysis",id:"uncertainty-analysis",level:3},{value:"Critical Constraints Identified",id:"critical-constraints-identified",level:3},{value:"Summary",id:"summary",level:2},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"Module 1 Complete",id:"module-1-complete",level:2},{value:"What&#39;s Next",id:"whats-next",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-4-physical-constraints-and-the-perception-action-loop",children:"Chapter 4: Physical Constraints and the Perception-Action Loop"})}),"\n",(0,i.jsx)(n.h2,{id:"chapter-goal",children:"Chapter Goal"}),"\n",(0,i.jsxs)(n.p,{children:["By the end of this chapter, you will be able to ",(0,i.jsx)(n.strong,{children:"synthesize your knowledge of sensors and actuators into a complete system view"}),", analyzing the timing budgets, uncertainty propagation, and physical constraints that govern real robotic systems. You will create physical constraints specifications for realistic tasks."]}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"ID"}),(0,i.jsx)(n.th,{children:"Objective"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4.1"}),(0,i.jsx)(n.td,{children:"Draw and label the complete perception-action loop for a given robotic system"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4.2"}),(0,i.jsx)(n.td,{children:"Calculate end-to-end latency budget for a perception-action loop"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4.3"}),(0,i.jsx)(n.td,{children:"Trace how sensor uncertainty propagates through processing to action uncertainty"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4.4"}),(0,i.jsx)(n.td,{children:"Identify timing constraints (hard real-time, soft real-time, best-effort) for system components"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4.5"}),(0,i.jsx)(n.td,{children:"Design a physical constraints specification for a given robotic task"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"the-problem-when-components-work-but-systems-fail",children:"The Problem: When Components Work but Systems Fail"}),"\n",(0,i.jsx)(n.p,{children:"An engineer builds a robot with:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A camera that works perfectly (30 fps, sharp images)"}),"\n",(0,i.jsx)(n.li,{children:"An object detector that works perfectly (95% accuracy)"}),"\n",(0,i.jsx)(n.li,{children:"A motion planner that works perfectly (optimal paths)"}),"\n",(0,i.jsx)(n.li,{children:"A motor controller that works perfectly (precise tracking)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Each component is tested and validated individually. But when integrated, the robot repeatedly misses moving objects."}),"\n",(0,i.jsx)(n.p,{children:"What went wrong?"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Camera: 30 fps \u2192 33 ms between frames"}),"\n",(0,i.jsx)(n.li,{children:"Object detection: 50 ms processing time"}),"\n",(0,i.jsx)(n.li,{children:"Motion planning: 20 ms computation"}),"\n",(0,i.jsx)(n.li,{children:"Motor response: 80 ms to reach target velocity"}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Total"}),": 33 + 50 + 20 + 80 = ",(0,i.jsx)(n.strong,{children:"183 ms"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["An object moving at 1 m/s travels ",(0,i.jsx)(n.strong,{children:"18 cm"})," in this time. The robot sees where the object ",(0,i.jsx)(n.em,{children:"was"}),", not where it ",(0,i.jsx)(n.em,{children:"is"}),"."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"The components work perfectly. The system fails because the engineer didn't analyze the complete perception-action loop."})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"complete-loop",children:"The Complete Perception-Action Loop"}),"\n",(0,i.jsx)(n.p,{children:"We introduced the perception-action loop in Chapter 1. Now we'll analyze it in full detail."}),"\n",(0,i.jsx)(n.h3,{id:"loop-components",children:"Loop Components"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                         ENVIRONMENT                                  \u2502\r\n\u2502                                                                      \u2502\r\n\u2502   Object State \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Object State         \u2502\r\n\u2502   at time t                                    at time t + \u0394t       \u2502\r\n\u2502        \u2502                                            \u25b2               \u2502\r\n\u2502        \u2502 Physical                                   \u2502 Physical      \u2502\r\n\u2502        \u2502 Process                                    \u2502 Change        \u2502\r\n\u2502        \u25bc                                            \u2502               \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n         \u2502                                            \u2502\r\n         \u2502 Light, Sound,                              \u2502 Force, Motion\r\n         \u2502 Force, etc.                                \u2502\r\n         \u25bc                                            \u2502\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502    SENSORS      \u2502                          \u2502   ACTUATORS     \u2502\r\n\u2502                 \u2502                          \u2502                 \u2502\r\n\u2502 \u2022 Transduction  \u2502                          \u2502 \u2022 Amplification \u2502\r\n\u2502 \u2022 Sampling      \u2502                          \u2502 \u2022 Conversion    \u2502\r\n\u2502 \u2022 Digitization  \u2502                          \u2502 \u2022 Transmission  \u2502\r\n\u2502                 \u2502                          \u2502                 \u2502\r\n\u2502 Latency: \u03c4_s    \u2502                          \u2502 Latency: \u03c4_a    \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n         \u2502                                            \u2502\r\n         \u2502 Sensor Data                       Commands \u2502\r\n         \u2502 (discrete, noisy)                 (discrete)\u2502\r\n         \u25bc                                            \u2502\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                           PROCESSING                                  \u2502\r\n\u2502                                                                       \u2502\r\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\r\n\u2502  \u2502  PERCEPTION  \u2502\u2500\u2500\u2500\u25ba\u2502   PLANNING   \u2502\u2500\u2500\u2500\u25ba\u2502  EXECUTION   \u2502           \u2502\r\n\u2502  \u2502              \u2502    \u2502              \u2502    \u2502              \u2502           \u2502\r\n\u2502  \u2502 \u2022 Detection  \u2502    \u2502 \u2022 Path plan  \u2502    \u2502 \u2022 Trajectory \u2502           \u2502\r\n\u2502  \u2502 \u2022 Estimation \u2502    \u2502 \u2022 Task plan  \u2502    \u2502 \u2022 Control    \u2502           \u2502\r\n\u2502  \u2502 \u2022 Fusion     \u2502    \u2502 \u2022 Decision   \u2502    \u2502 \u2022 Safety     \u2502           \u2502\r\n\u2502  \u2502              \u2502    \u2502              \u2502    \u2502              \u2502           \u2502\r\n\u2502  \u2502 Latency: \u03c4_p \u2502    \u2502 Latency: \u03c4_l \u2502    \u2502 Latency: \u03c4_e \u2502           \u2502\r\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\r\n\u2502                                                                       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h3,{id:"latency-budget",children:"Latency Budget"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Total loop latency"})," = \u03c4_s + \u03c4_p + \u03c4_l + \u03c4_e + \u03c4_a"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Symbol"}),(0,i.jsx)(n.th,{children:"Typical Range"}),(0,i.jsx)(n.th,{children:"Example"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Sensor"}),(0,i.jsx)(n.td,{children:"\u03c4_s"}),(0,i.jsx)(n.td,{children:"1-100 ms"}),(0,i.jsx)(n.td,{children:"Camera: 33 ms (at 30 fps)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Perception"}),(0,i.jsx)(n.td,{children:"\u03c4_p"}),(0,i.jsx)(n.td,{children:"10-200 ms"}),(0,i.jsx)(n.td,{children:"Object detection: 50 ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Planning"}),(0,i.jsx)(n.td,{children:"\u03c4_l"}),(0,i.jsx)(n.td,{children:"1-100 ms"}),(0,i.jsx)(n.td,{children:"Motion planning: 20 ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Execution"}),(0,i.jsx)(n.td,{children:"\u03c4_e"}),(0,i.jsx)(n.td,{children:"0.1-10 ms"}),(0,i.jsx)(n.td,{children:"Control loop: 1 ms"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Actuator"}),(0,i.jsx)(n.td,{children:"\u03c4_a"}),(0,i.jsx)(n.td,{children:"10-200 ms"}),(0,i.jsx)(n.td,{children:"Motor response: 80 ms"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"why-latency-matters",children:"Why Latency Matters"}),"\n",(0,i.jsx)(n.p,{children:"For a dynamic task, the system must respond faster than the environment changes:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Task"}),(0,i.jsx)(n.th,{children:"Required Response Time"}),(0,i.jsx)(n.th,{children:"Typical Latency"}),(0,i.jsx)(n.th,{children:"Feasible?"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Balancing (standing)"}),(0,i.jsx)(n.td,{children:"50-100 ms"}),(0,i.jsx)(n.td,{children:"30-50 ms"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Catching thrown ball"}),(0,i.jsx)(n.td,{children:"200-400 ms"}),(0,i.jsx)(n.td,{children:"150-200 ms"}),(0,i.jsx)(n.td,{children:"Marginal"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Avoiding fast obstacle"}),(0,i.jsx)(n.td,{children:"100-200 ms"}),(0,i.jsx)(n.td,{children:"150-200 ms"}),(0,i.jsx)(n.td,{children:"Marginal"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Tracking walking person"}),(0,i.jsx)(n.td,{children:"500+ ms"}),(0,i.jsx)(n.td,{children:"150-200 ms"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Static manipulation"}),(0,i.jsx)(n.td,{children:"Seconds"}),(0,i.jsx)(n.td,{children:"150-200 ms"}),(0,i.jsx)(n.td,{children:"Yes"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Physical Grounding"}),": The latency budget is a hard physical constraint. No amount of software optimization can make a 30 fps camera produce data faster than 33 ms per frame."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"latency-analysis",children:"Latency Budget Analysis"}),"\n",(0,i.jsx)(n.p,{children:"Let's work through a detailed example."}),"\n",(0,i.jsx)(n.h3,{id:"example-ball-catching-robot",children:"Example: Ball-Catching Robot"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Task"}),": Catch a ball thrown at 10 m/s from 3 meters away"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Available time"}),": 3 m \xf7 10 m/s = ",(0,i.jsx)(n.strong,{children:"300 ms"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"System components"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Latency"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Camera capture"}),(0,i.jsx)(n.td,{children:"8 ms"}),(0,i.jsx)(n.td,{children:"120 fps high-speed camera"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Image transfer"}),(0,i.jsx)(n.td,{children:"2 ms"}),(0,i.jsx)(n.td,{children:"USB 3.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Ball detection"}),(0,i.jsx)(n.td,{children:"15 ms"}),(0,i.jsx)(n.td,{children:"GPU-accelerated"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Trajectory prediction"}),(0,i.jsx)(n.td,{children:"5 ms"}),(0,i.jsx)(n.td,{children:"Kalman filter"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motion planning"}),(0,i.jsx)(n.td,{children:"10 ms"}),(0,i.jsx)(n.td,{children:"Pre-computed catch poses"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Command transmission"}),(0,i.jsx)(n.td,{children:"1 ms"}),(0,i.jsx)(n.td,{children:"EtherCAT"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motor response"}),(0,i.jsx)(n.td,{children:"60 ms"}),(0,i.jsx)(n.td,{children:"Including acceleration"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Total"}),": 8 + 2 + 15 + 5 + 10 + 1 + 60 = ",(0,i.jsx)(n.strong,{children:"101 ms"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Margin"}),": 300 - 101 = ",(0,i.jsx)(n.strong,{children:"199 ms"})," for trajectory updates"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Conclusion"}),": System is feasible with significant margin for multiple perception-action cycles during the catch."]}),"\n",(0,i.jsx)(n.h3,{id:"what-if-we-used-standard-components",children:"What If We Used Standard Components?"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Latency"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Camera capture"}),(0,i.jsx)(n.td,{children:"33 ms"}),(0,i.jsx)(n.td,{children:"30 fps standard camera"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Image transfer"}),(0,i.jsx)(n.td,{children:"10 ms"}),(0,i.jsx)(n.td,{children:"USB 2.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Ball detection"}),(0,i.jsx)(n.td,{children:"100 ms"}),(0,i.jsx)(n.td,{children:"CPU processing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Trajectory prediction"}),(0,i.jsx)(n.td,{children:"20 ms"}),(0,i.jsx)(n.td,{children:"Non-optimized"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motion planning"}),(0,i.jsx)(n.td,{children:"50 ms"}),(0,i.jsx)(n.td,{children:"Full replan each cycle"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Command transmission"}),(0,i.jsx)(n.td,{children:"5 ms"}),(0,i.jsx)(n.td,{children:"CAN bus"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motor response"}),(0,i.jsx)(n.td,{children:"100 ms"}),(0,i.jsx)(n.td,{children:"Consumer motors"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Total"}),": 33 + 10 + 100 + 20 + 50 + 5 + 100 = ",(0,i.jsx)(n.strong,{children:"318 ms"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Result"}),": ",(0,i.jsx)(n.strong,{children:"System cannot catch the ball"})," (318 ms > 300 ms available)"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"uncertainty-propagation",children:"Uncertainty Propagation"}),"\n",(0,i.jsx)(n.p,{children:"Sensor noise doesn't stay at the sensor\u2014it propagates through the entire system."}),"\n",(0,i.jsx)(n.h3,{id:"sources-of-uncertainty",children:"Sources of Uncertainty"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Stage"}),(0,i.jsx)(n.th,{children:"Uncertainty Source"}),(0,i.jsx)(n.th,{children:"Typical Magnitude"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Sensor"}),(0,i.jsx)(n.td,{children:"Measurement noise"}),(0,i.jsx)(n.td,{children:"\xb11-10 cm (position), \xb10.1-1\xb0 (angle)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Perception"}),(0,i.jsx)(n.td,{children:"Detection error"}),(0,i.jsx)(n.td,{children:"\xb15-20 cm (object position)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"State estimation"}),(0,i.jsx)(n.td,{children:"Filter uncertainty"}),(0,i.jsx)(n.td,{children:"Depends on motion model"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Planning"}),(0,i.jsx)(n.td,{children:"Model error"}),(0,i.jsx)(n.td,{children:"Path may not be executable"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Execution"}),(0,i.jsx)(n.td,{children:"Tracking error"}),(0,i.jsx)(n.td,{children:"\xb11-5 mm (industrial), \xb11-5 cm (mobile)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Actuator"}),(0,i.jsx)(n.td,{children:"Positioning error"}),(0,i.jsx)(n.td,{children:"\xb10.1-10 mm (depends on type)"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"propagation-example",children:"Propagation Example"}),"\n",(0,i.jsx)(n.p,{children:"Consider a robot arm picking an object:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Camera measures object at position (x, y, z) with uncertainty \u03c3_cam = \xb15 mm"})}),"\n",(0,i.jsx)(n.p,{children:"\u2193"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Transform to robot frame adds calibration error: \u03c3_cal = \xb12 mm"})}),"\n",(0,i.jsxs)(n.p,{children:["Combined: \u03c3 = \u221a(5\xb2 + 2\xb2) = ",(0,i.jsx)(n.strong,{children:"\xb15.4 mm"})]}),"\n",(0,i.jsx)(n.p,{children:"\u2193"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Inverse kinematics has numerical error: \u03c3_ik = \xb10.5 mm"})}),"\n",(0,i.jsxs)(n.p,{children:["Combined: \u03c3 = \u221a(5.4\xb2 + 0.5\xb2) = ",(0,i.jsx)(n.strong,{children:"\xb15.4 mm"})," (IK error negligible)"]}),"\n",(0,i.jsx)(n.p,{children:"\u2193"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Joint controllers have tracking error: \u03c3_joint = \xb10.1\xb0 per joint"})}),"\n",(0,i.jsxs)(n.p,{children:["For 6 joints at 0.5 m arm length: \u03c3_ee \u2248 ",(0,i.jsx)(n.strong,{children:"\xb13 mm"})]}),"\n",(0,i.jsxs)(n.p,{children:["Combined: \u03c3 = \u221a(5.4\xb2 + 3\xb2) = ",(0,i.jsx)(n.strong,{children:"\xb16.2 mm"})]}),"\n",(0,i.jsx)(n.p,{children:"\u2193"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Gripper positioning error: \u03c3_grip = \xb11 mm"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Final end-effector uncertainty: \u03c3_total = \u221a(6.2\xb2 + 1\xb2) \u2248 \xb16.3 mm"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Physical Grounding"}),": If the object is 5 mm smaller than the gripper opening, the \xb16.3 mm uncertainty means the grasp may fail 30%+ of the time. The camera noise propagates all the way to grasp success rate."]}),"\n",(0,i.jsx)(n.h3,{id:"reducing-uncertainty",children:"Reducing Uncertainty"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Strategy"}),(0,i.jsx)(n.th,{children:"Mechanism"}),(0,i.jsx)(n.th,{children:"Cost"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Better sensors"}),(0,i.jsx)(n.td,{children:"Lower \u03c3_cam"}),(0,i.jsx)(n.td,{children:"Higher $$$"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Better calibration"}),(0,i.jsx)(n.td,{children:"Lower \u03c3_cal"}),(0,i.jsx)(n.td,{children:"Time, expertise"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Sensor fusion"}),(0,i.jsx)(n.td,{children:"Combine multiple measurements"}),(0,i.jsx)(n.td,{children:"Complexity"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Visual servoing"}),(0,i.jsx)(n.td,{children:"Closed-loop with vision"}),(0,i.jsx)(n.td,{children:"Slower, complex"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Compliance"}),(0,i.jsx)(n.td,{children:"Tolerate position error"}),(0,i.jsx)(n.td,{children:"May not work for all tasks"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"realtime-requirements",children:"Real-Time Requirements"}),"\n",(0,i.jsx)(n.p,{children:"Not all timing constraints are equal. Understanding the taxonomy helps set correct priorities."}),"\n",(0,i.jsx)(n.h3,{id:"hard-real-time",children:"Hard Real-Time"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Definition"}),": Missing a deadline causes system failure."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Examples"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Motor control loop (1 kHz): Miss deadline \u2192 unstable control, motor damage"}),"\n",(0,i.jsx)(n.li,{children:"Balance control (100 Hz): Miss deadline \u2192 robot falls"}),"\n",(0,i.jsx)(n.li,{children:"Safety monitoring: Miss deadline \u2192 collision not avoided"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Implementation"}),": Requires real-time operating system (RTOS), deterministic hardware, careful software design."]}),"\n",(0,i.jsx)(n.h3,{id:"soft-real-time",children:"Soft Real-Time"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Definition"}),": Missing occasional deadlines degrades performance but doesn't cause failure."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Examples"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Path planning updates: Late plan \u2192 suboptimal path, not failure"}),"\n",(0,i.jsx)(n.li,{children:"Display updates: Delayed frame \u2192 visual glitch, not failure"}),"\n",(0,i.jsx)(n.li,{children:"Logging: Late log \u2192 data out of order, not failure"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Implementation"}),": Can use standard OS with careful priority management."]}),"\n",(0,i.jsx)(n.h3,{id:"best-effort",children:"Best-Effort"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Definition"}),": No deadline; complete when resources allow."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Examples"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Map building in SLAM"}),"\n",(0,i.jsx)(n.li,{children:"Learning/adaptation"}),"\n",(0,i.jsx)(n.li,{children:"User interface updates"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"classifying-system-components",children:"Classifying System Components"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Typical Requirement"}),(0,i.jsx)(n.th,{children:"Justification"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motor current control"}),(0,i.jsx)(n.td,{children:"Hard (1-10 kHz)"}),(0,i.jsx)(n.td,{children:"Motor physics"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Joint position control"}),(0,i.jsx)(n.td,{children:"Hard (100-1000 Hz)"}),(0,i.jsx)(n.td,{children:"Stability"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Balance/stabilization"}),(0,i.jsx)(n.td,{children:"Hard (50-200 Hz)"}),(0,i.jsx)(n.td,{children:"Don't fall"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Collision avoidance"}),(0,i.jsx)(n.td,{children:"Hard (10-100 Hz)"}),(0,i.jsx)(n.td,{children:"Safety"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Path tracking"}),(0,i.jsx)(n.td,{children:"Soft (10-50 Hz)"}),(0,i.jsx)(n.td,{children:"Performance"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Perception pipeline"}),(0,i.jsx)(n.td,{children:"Soft (10-30 Hz)"}),(0,i.jsx)(n.td,{children:"Performance"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Motion planning"}),(0,i.jsx)(n.td,{children:"Soft (1-10 Hz)"}),(0,i.jsx)(n.td,{children:"Performance"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Task planning"}),(0,i.jsx)(n.td,{children:"Best-effort"}),(0,i.jsx)(n.td,{children:"Correctness > speed"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"constraints-spec",children:"Physical Constraints Specification"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"physical constraints specification"})," documents all the physical factors that bound what a system can achieve."]}),"\n",(0,i.jsx)(n.h3,{id:"specification-template",children:"Specification Template"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-markdown",children:"# Physical Constraints Specification: [Task Name]\r\n\r\n## Task Description\r\n[What the robot must do]\r\n\r\n## Timing Constraints\r\n\r\n### Deadlines\r\n| Constraint | Value | Type | Justification |\r\n|------------|-------|------|---------------|\r\n| [name] | [time] | [hard/soft/best-effort] | [why] |\r\n\r\n### Latency Budget\r\n| Component | Latency | Notes |\r\n|-----------|---------|-------|\r\n| [component] | [time] | [details] |\r\n\r\n**Total loop latency**: [sum]\r\n**Required response time**: [time]\r\n**Margin**: [difference]\r\n\r\n## Spatial Constraints\r\n\r\n### Workspace\r\n- Volume: [dimensions]\r\n- Obstacles: [description]\r\n- Access constraints: [description]\r\n\r\n### Precision Requirements\r\n| Dimension | Required | Achievable | Margin |\r\n|-----------|----------|------------|--------|\r\n| Position | [\xb1X mm] | [\xb1Y mm] | [\xb1Z mm] |\r\n| Orientation | [\xb1X\xb0] | [\xb1Y\xb0] | [\xb1Z\xb0] |\r\n\r\n## Force/Load Constraints\r\n\r\n| Constraint | Value | Justification |\r\n|------------|-------|---------------|\r\n| Maximum payload | [kg] | [why] |\r\n| Maximum contact force | [N] | [safety/task] |\r\n| Continuous load | [kg] | [thermal limits] |\r\n\r\n## Environmental Constraints\r\n\r\n| Factor | Requirement | Sensor/Actuator Impact |\r\n|--------|-------------|------------------------|\r\n| Temperature | [range] | [effects] |\r\n| Lighting | [conditions] | [camera implications] |\r\n| Noise | [level] | [audio sensor implications] |\r\n\r\n## Uncertainty Budget\r\n\r\n| Source | Magnitude | Propagates To |\r\n|--------|-----------|---------------|\r\n| [source] | [\xb1value] | [affected quantities] |\r\n\r\n**Total uncertainty at end-effector**: [\xb1value]\r\n\r\n## Safety Constraints\r\n\r\n| Constraint | Limit | Mechanism |\r\n|------------|-------|-----------|\r\n| Maximum velocity | [m/s] | [how enforced] |\r\n| Maximum force | [N] | [how enforced] |\r\n| Emergency stop time | [ms] | [how achieved] |\r\n\r\n## Critical Constraints\r\n\r\n[List the 3-5 constraints most likely to cause system failure if violated]\r\n\r\n1. [Constraint]: [Why critical]\r\n2. [Constraint]: [Why critical]\r\n3. [Constraint]: [Why critical]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"example-pick-and-place-coffee-cup",children:"Example: Pick and Place Coffee Cup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-markdown",children:"# Physical Constraints Specification: Coffee Cup Pick and Place\r\n\r\n## Task Description\r\nPick a coffee cup from a table and place it in a dishwasher rack\r\n\r\n## Timing Constraints\r\n\r\n### Deadlines\r\n| Constraint | Value | Type | Justification |\r\n|------------|-------|------|---------------|\r\n| Cup detection | 500 ms | Soft | User waiting |\r\n| Grasp execution | N/A | Best-effort | Static scene |\r\n| Collision avoidance | 100 ms | Hard | Safety near humans |\r\n\r\n### Latency Budget\r\n| Component | Latency | Notes |\r\n|-----------|---------|-------|\r\n| Camera capture | 33 ms | 30 fps RGB-D |\r\n| Cup detection | 80 ms | Neural network |\r\n| Grasp planning | 200 ms | GraspNet |\r\n| Motion planning | 150 ms | MoveIt |\r\n| Motor response | 100 ms | 7-DOF arm |\r\n\r\n**Total loop latency**: 563 ms\r\n**Required response time**: Not constrained (static cup)\r\n**Margin**: Adequate for static task\r\n\r\n## Spatial Constraints\r\n\r\n### Workspace\r\n- Volume: 0.8m \xd7 0.6m \xd7 0.4m (table surface)\r\n- Obstacles: Other dishes, table edges\r\n- Access: Approach from above only\r\n\r\n### Precision Requirements\r\n| Dimension | Required | Achievable | Margin |\r\n|-----------|----------|------------|--------|\r\n| Position | \xb110 mm | \xb15 mm | \xb15 mm |\r\n| Orientation | \xb15\xb0 | \xb12\xb0 | \xb13\xb0 |\r\n\r\n## Force/Load Constraints\r\n\r\n| Constraint | Value | Justification |\r\n|------------|-------|---------------|\r\n| Maximum payload | 0.5 kg | Cup + liquid |\r\n| Maximum grip force | 20 N | Don't crush cup |\r\n| Minimum grip force | 5 N | Don't drop cup |\r\n\r\n## Uncertainty Budget\r\n\r\n| Source | Magnitude | Propagates To |\r\n|--------|-----------|---------------|\r\n| Depth camera | \xb13 mm | Cup position |\r\n| Hand-eye calibration | \xb12 mm | Grasp pose |\r\n| Joint tracking | \xb12 mm | End-effector |\r\n\r\n**Total uncertainty at end-effector**: \xb14.1 mm\r\n\r\n## Safety Constraints\r\n\r\n| Constraint | Limit | Mechanism |\r\n|------------|-------|-----------|\r\n| Max velocity | 0.5 m/s | Software limit |\r\n| Max force | 50 N | Current limiting |\r\n| E-stop time | 100 ms | Motor STO |\r\n\r\n## Critical Constraints\r\n\r\n1. **Grip force**: Too high crushes cup, too low drops it\r\n2. **Position accuracy**: Must be within \xb110 mm for reliable grasp\r\n3. **Collision avoidance**: Human may reach into workspace\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"case-study",children:"Case Study: Analyzing a Complete System"}),"\n",(0,i.jsx)(n.p,{children:"Let's analyze a warehouse mobile manipulator that picks items from shelves."}),"\n",(0,i.jsx)(n.h3,{id:"system-components",children:"System Components"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mobile base"}),": Differential drive, odometry + LIDAR localization"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Arm"}),": 6-DOF collaborative arm"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gripper"}),": Parallel jaw"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensors"}),": 2D LIDAR, RGB-D camera, joint encoders"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"perception-action-loop",children:"Perception-Action Loop"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"LIDAR (10 Hz) \u2500\u2500\u25ba Localization (50 Hz) \u2500\u2500\u25ba Navigation (10 Hz) \u2500\u2500\u25ba Base control (50 Hz)\r\n                        \u2502\r\nCamera (30 Hz) \u2500\u2500\u25ba Object detection \u2500\u2500\u25ba Grasp planning \u2500\u2500\u25ba Arm control (100 Hz)\r\n                        \u2502\r\n                        \u25bc\r\n                  Task coordination\n"})}),"\n",(0,i.jsx)(n.h3,{id:"timing-analysis",children:"Timing Analysis"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Navigation loop"}),": 100 ms LIDAR + 20 ms localization + 50 ms planning + 20 ms control = ",(0,i.jsx)(n.strong,{children:"190 ms"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"At 1 m/s, robot travels 19 cm between perception updates"}),"\n",(0,i.jsx)(n.li,{children:"Acceptable for warehouse navigation"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Manipulation loop"}),": 33 ms camera + 100 ms detection + 200 ms grasp planning + 10 ms control = ",(0,i.jsx)(n.strong,{children:"343 ms"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Object is stationary, so latency is not critical"}),"\n",(0,i.jsx)(n.li,{children:"But human approaching at 1.5 m/s travels 51 cm in this time \u2192 safety concern"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"uncertainty-analysis",children:"Uncertainty Analysis"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Mobile base position"}),": \xb15 cm (LIDAR SLAM) + \xb12 cm (drift between updates) = ",(0,i.jsx)(n.strong,{children:"\xb15.4 cm"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"End-effector position"}),": \xb15.4 cm (base) + \xb13 cm (arm calibration) + \xb12 cm (arm tracking) = ",(0,i.jsx)(n.strong,{children:"\xb16.5 cm"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Grasp success"}),": With \xb16.5 cm uncertainty and 10 cm gripper opening, grasp reliability is marginal. ",(0,i.jsx)(n.strong,{children:"Visual servoing needed"})," to close the loop with the camera before final grasp."]}),"\n",(0,i.jsx)(n.h3,{id:"critical-constraints-identified",children:"Critical Constraints Identified"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety response time"})," (100 ms) may be insufficient if detection takes 343 ms"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Base position uncertainty"})," (\xb15.4 cm) limits manipulation without visual servoing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation update rate"})," (190 ms) limits speed in dynamic environments"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"This chapter integrated sensors and actuators into complete system analysis:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The perception-action loop"})," is the fundamental architecture; its total latency determines what tasks are feasible."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Latency budget analysis"})," adds up all delays from sensor to actuator; this determines if a system can respond fast enough."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Uncertainty propagates"})," through the entire loop; camera noise becomes grasp failure rate."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Real-time requirements"})," are classified as hard (must meet), soft (should meet), or best-effort (no deadline)."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Physical constraints specifications"})," document all the timing, spatial, force, and uncertainty constraints that govern a system."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Latency Budget"}),": A robot must catch objects dropped from 1 meter height (falling time \u2248 450 ms). Your system has: camera 16 ms, detection 40 ms, planning 30 ms, control 2 ms, motor response 150 ms. Is the system feasible? What is the margin?"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Uncertainty Propagation"}),": A depth camera has \xb110 mm accuracy. The robot arm has \xb13 mm repeatability. The gripper can grasp objects that are within \xb18 mm of the target position. Will the system reliably grasp objects? What is the limiting factor?"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Real-Time Classification"}),": Classify each as hard, soft, or best-effort real-time: (a) motor current control, (b) updating a map for navigation, (c) sending status to a remote operator, (d) avoiding a moving obstacle."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Constraints Specification"}),": Write a physical constraints specification for a robot that pours liquid from a bottle into a glass. Include timing, precision, and force constraints."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"System Analysis"}),": A self-driving car has sensor latency of 50 ms and total processing latency of 200 ms. At 60 mph (27 m/s), how far does the car travel during this latency? What implications does this have for stopping distance calculations?"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"module-1-complete",children:"Module 1 Complete"}),"\n",(0,i.jsx)(n.p,{children:"Congratulations on completing Module 1: Physical AI Foundations!"}),"\n",(0,i.jsx)(n.p,{children:"You now have the mental model that will guide all subsequent learning:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Embodied intelligence"})," faces constraints that software-only AI does not"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensors"})," provide noisy, limited windows into the physical world"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuators"})," provide limited, imperfect means of affecting the world"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physical constraints"})," govern what any robotic system can achieve"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.a,{href:"/module-2",children:"Module 2: ROS 2 Fundamentals"}),", you'll learn to implement these concepts in code:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Sensors become ",(0,i.jsx)(n.strong,{children:"topics"})," you subscribe to"]}),"\n",(0,i.jsxs)(n.li,{children:["Actuators become ",(0,i.jsx)(n.strong,{children:"commands"})," you publish"]}),"\n",(0,i.jsxs)(n.li,{children:["The perception-action loop becomes ",(0,i.jsx)(n.strong,{children:"nodes"})," connected by messages"]}),"\n",(0,i.jsxs)(n.li,{children:["Timing constraints become ",(0,i.jsx)(n.strong,{children:"QoS policies"})," and ",(0,i.jsx)(n.strong,{children:"node design"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The physical grounding you've built in Module 1 will inform every design decision in Module 2 and beyond."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>l,x:()=>a});var t=s(6540);const i={},r=t.createContext(i);function l(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);