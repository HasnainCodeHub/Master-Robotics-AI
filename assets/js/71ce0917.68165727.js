"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[8910],{2776(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"appendix/ml-concepts-roboticists","title":"Appendix A: ML Concepts for Roboticists","description":"This appendix provides a conceptual foundation for understanding the machine learning components used in this course, particularly in Module 5 (Vision-Language-Action Systems). You don\'t need to implement these systems from scratch\u2014the goal is understanding how to use them effectively.","source":"@site/docs/appendix/ml-concepts-roboticists.md","sourceDirName":"appendix","slug":"/appendix/ml-concepts-roboticists","permalink":"/Master-Robotics-AI/textbook/appendix/ml-concepts-roboticists","draft":false,"unlisted":false,"editUrl":"https://github.com/HasnainCodeHub/Master-Robotics-AI/tree/main/docs/docs/appendix/ml-concepts-roboticists.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ml-concepts-roboticists","title":"Appendix A: ML Concepts for Roboticists","sidebar_label":"A. ML Concepts","sidebar_position":2},"sidebar":"textbookSidebar","previous":{"title":"Appendices","permalink":"/Master-Robotics-AI/textbook/appendix/"},"next":{"title":"B. Hardware Requirements","permalink":"/Master-Robotics-AI/textbook/appendix/hardware-requirements"}}');var s=i(4848),r=i(8453);const l={id:"ml-concepts-roboticists",title:"Appendix A: ML Concepts for Roboticists",sidebar_label:"A. ML Concepts",sidebar_position:2},d="Appendix A: Machine Learning Concepts for Roboticists",o={},c=[{value:"What You Need to Know (and What You Don&#39;t)",id:"scope",level:2},{value:"Required Understanding",id:"required-understanding",level:3},{value:"Not Required",id:"not-required",level:3},{value:"Neural Networks: Function Approximators",id:"neural-networks",level:2},{value:"The Core Idea",id:"the-core-idea",level:3},{value:"Why This Matters for Robotics",id:"why-this-matters-for-robotics",level:3},{value:"Key Limitation: Training Distribution",id:"key-limitation-training-distribution",level:3},{value:"Embeddings: Meaning as Numbers",id:"embeddings",level:2},{value:"What Are Embeddings?",id:"what-are-embeddings",level:3},{value:"Similarity Through Distance",id:"similarity-through-distance",level:3},{value:"Why This Matters for Robotics",id:"why-this-matters-for-robotics-1",level:3},{value:"Key Numbers to Know",id:"key-numbers-to-know",level:3},{value:"Transformers: Context Matters",id:"transformers",level:2},{value:"The Problem: Order and Context",id:"the-problem-order-and-context",level:3},{value:"The Solution: Attention",id:"the-solution-attention",level:3},{value:"Why This Matters for Robotics",id:"why-this-matters-for-robotics-2",level:3},{value:"Key Limitations",id:"key-limitations",level:3},{value:"Model Types in VLA Systems",id:"model-types",level:2},{value:"Speech Recognition (Whisper)",id:"speech-recognition-whisper",level:3},{value:"Large Language Models (LLMs)",id:"large-language-models-llms",level:3},{value:"Vision-Language Models (VLMs)",id:"vision-language-models-vlms",level:3},{value:"Latency Expectations",id:"latency",level:2},{value:"Typical Inference Times",id:"typical-inference-times",level:3},{value:"Budget Allocation for VLA",id:"budget-allocation-for-vla",level:3},{value:"Common Failure Modes",id:"failures",level:2},{value:"Hallucination",id:"hallucination",level:3},{value:"Out-of-Distribution",id:"out-of-distribution",level:3},{value:"Context Length Overflow",id:"context-length-overflow",level:3},{value:"Latency Spike",id:"latency-spike",level:3},{value:"Practical Guidelines",id:"guidelines",level:2},{value:"When to Use Neural Networks",id:"when-to-use-neural-networks",level:3},{value:"Integration Best Practices",id:"integration-best-practices",level:3},{value:"Questions to Ask Before Using a Model",id:"questions-to-ask-before-using-a-model",level:3},{value:"Summary",id:"summary",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"appendix-a-machine-learning-concepts-for-roboticists",children:"Appendix A: Machine Learning Concepts for Roboticists"})}),"\n",(0,s.jsx)(n.p,{children:"This appendix provides a conceptual foundation for understanding the machine learning components used in this course, particularly in Module 5 (Vision-Language-Action Systems). You don't need to implement these systems from scratch\u2014the goal is understanding how to use them effectively."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"scope",children:"What You Need to Know (and What You Don't)"}),"\n",(0,s.jsx)(n.h3,{id:"required-understanding",children:"Required Understanding"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Concept"}),(0,s.jsx)(n.th,{children:"Why It Matters"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What neural networks do"}),(0,s.jsx)(n.td,{children:"Understand capability boundaries"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"How embeddings work"}),(0,s.jsx)(n.td,{children:"Configure VLM queries effectively"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Why transformers process sequences"}),(0,s.jsx)(n.td,{children:"Debug context length issues"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What latency to expect"}),(0,s.jsx)(n.td,{children:"Budget time in VLA pipeline"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"not-required",children:"Not Required"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Backpropagation mathematics"}),"\n",(0,s.jsx)(n.li,{children:"Model training procedures"}),"\n",(0,s.jsx)(n.li,{children:"Architecture design decisions"}),"\n",(0,s.jsx)(n.li,{children:"Loss function derivation"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"neural-networks",children:"Neural Networks: Function Approximators"}),"\n",(0,s.jsx)(n.h3,{id:"the-core-idea",children:"The Core Idea"}),"\n",(0,s.jsxs)(n.p,{children:["A neural network is a ",(0,s.jsx)(n.strong,{children:"function approximator"}),"\u2014it learns to map inputs to outputs from examples."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Input (image) \u2192 Neural Network \u2192 Output (classification)\r\nInput (text)  \u2192 Neural Network \u2192 Output (text)\r\nInput (audio) \u2192 Neural Network \u2192 Output (transcript)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"why-this-matters-for-robotics",children:"Why This Matters for Robotics"}),"\n",(0,s.jsx)(n.p,{children:"Neural networks can learn mappings that are difficult to program explicitly:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Task"}),(0,s.jsx)(n.th,{children:"Traditional Approach"}),(0,s.jsx)(n.th,{children:"Neural Network Approach"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Object detection"}),(0,s.jsx)(n.td,{children:"Hand-coded features + rules"}),(0,s.jsx)(n.td,{children:"Learn features from examples"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Speech recognition"}),(0,s.jsx)(n.td,{children:"Acoustic models + grammars"}),(0,s.jsx)(n.td,{children:"End-to-end learning"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Navigation"}),(0,s.jsx)(n.td,{children:"Explicit path planning"}),(0,s.jsx)(n.td,{children:"Learn from demonstrations"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"key-limitation-training-distribution",children:"Key Limitation: Training Distribution"}),"\n",(0,s.jsx)(n.p,{children:"Neural networks work well when inputs match their training data. They may fail unpredictably on:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Novel objects not in training set"}),"\n",(0,s.jsx)(n.li,{children:"Unusual lighting or camera angles"}),"\n",(0,s.jsx)(n.li,{children:"Accents or background noise not in training"}),"\n",(0,s.jsx)(n.li,{children:"Environments very different from simulation"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Implication"}),": Always verify neural network outputs in safety-critical applications."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"embeddings",children:"Embeddings: Meaning as Numbers"}),"\n",(0,s.jsx)(n.h3,{id:"what-are-embeddings",children:"What Are Embeddings?"}),"\n",(0,s.jsxs)(n.p,{children:["Embeddings are ",(0,s.jsx)(n.strong,{children:"numerical representations of meaning"}),". They convert text, images, or other data into vectors (lists of numbers) where similar items have similar vectors."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'"dog"  \u2192 [0.2, 0.8, 0.1, ...]\r\n"cat"  \u2192 [0.3, 0.7, 0.2, ...]  \u2190 Similar to dog\r\n"car"  \u2192 [0.9, 0.1, 0.3, ...]  \u2190 Different from dog\n'})}),"\n",(0,s.jsx)(n.h3,{id:"similarity-through-distance",children:"Similarity Through Distance"}),"\n",(0,s.jsx)(n.p,{children:"Similar concepts have embeddings that are close in vector space:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'cosine_similarity("dog", "cat") = 0.92  \u2190 High (similar)\r\ncosine_similarity("dog", "car") = 0.21  \u2190 Low (different)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"why-this-matters-for-robotics-1",children:"Why This Matters for Robotics"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Semantic Search"}),": Find relevant information by meaning, not just keywords."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Query: "How do I make the robot arm move?"\r\nEmbedding matches:\r\n  - "Joint trajectory control"\r\n  - "MoveIt motion planning"\r\n  - "Arm kinematics"\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"VLM Grounding"}),": Match language to visual features."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'"the red mug" \u2192 embedding \u2192 find object with similar visual embedding\n'})}),"\n",(0,s.jsx)(n.h3,{id:"key-numbers-to-know",children:"Key Numbers to Know"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Embedding Dimensions"}),(0,s.jsx)(n.th,{children:"Typical Use"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"OpenAI text-embedding-3"}),(0,s.jsx)(n.td,{children:"1536"}),(0,s.jsx)(n.td,{children:"Text similarity"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CLIP"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"Image-text matching"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Sentence-BERT"}),(0,s.jsx)(n.td,{children:"384-768"}),(0,s.jsx)(n.td,{children:"Semantic search"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"transformers",children:"Transformers: Context Matters"}),"\n",(0,s.jsx)(n.h3,{id:"the-problem-order-and-context",children:"The Problem: Order and Context"}),"\n",(0,s.jsx)(n.p,{children:"Traditional neural networks process each input independently. But meaning often depends on context:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'"I saw the bat" - Is it an animal or sports equipment?\r\n"Pick up the mug" - Which mug if there are several?\n'})}),"\n",(0,s.jsx)(n.h3,{id:"the-solution-attention",children:"The Solution: Attention"}),"\n",(0,s.jsxs)(n.p,{children:["Transformers use ",(0,s.jsx)(n.strong,{children:"attention"})," to relate each part of the input to every other part:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'"The red mug on the left"\r\n      \u2502      \u2502        \u2502\r\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n             \u2502\r\n    attention: "red" and "left" both describe "mug"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"why-this-matters-for-robotics-2",children:"Why This Matters for Robotics"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"LLM Task Planning"}),": The model considers the entire command when generating plans."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'"Pick up the mug and put it on the shelf"\r\n                    \u2502\r\n                    \u2514\u2500\u2500 "it" refers to "mug" (resolved via attention)\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"VLM Scene Understanding"}),": The model relates image regions to text queries."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Image: [table, mug, keyboard, mouse]\r\nQuery: "What is next to the keyboard?"\r\nAnswer: "mouse" (attention links spatial relationship to objects)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"key-limitations",children:"Key Limitations"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Context Window"}),": Maximum input length (e.g., 8K, 32K tokens). Plan for truncation."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Latency"}),": Scales with sequence length. Longer inputs = slower responses."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"model-types",children:"Model Types in VLA Systems"}),"\n",(0,s.jsx)(n.h3,{id:"speech-recognition-whisper",children:"Speech Recognition (Whisper)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Audio waveform (16kHz samples)\r\n",(0,s.jsx)(n.strong,{children:"Output"}),": Text transcript"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Audio: [waveform samples] \u2192 Whisper \u2192 "Pick up the red mug"\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Parameters"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Model size: tiny (fastest) to large (most accurate)"}),"\n",(0,s.jsx)(n.li,{children:"Language: English, multilingual"}),"\n",(0,s.jsx)(n.li,{children:"Task: transcribe (same language) or translate (to English)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"large-language-models-llms",children:"Large Language Models (LLMs)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Text (prompt + context)\r\n",(0,s.jsx)(n.strong,{children:"Output"}),": Text (completion)"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Prompt: "Convert to robot commands: pick up the mug"\r\nOutput: {"action": "pick", "target": "mug"}\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Parameters"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Temperature: 0 (deterministic) to 1 (creative)"}),"\n",(0,s.jsx)(n.li,{children:"Max tokens: Output length limit"}),"\n",(0,s.jsx)(n.li,{children:"System prompt: Instructions that guide behavior"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"vision-language-models-vlms",children:"Vision-Language Models (VLMs)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Image + Text query\r\n",(0,s.jsx)(n.strong,{children:"Output"}),": Text answer about the image"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Image: [photo of desk]\r\nQuery: "Where is the red object?"\r\nOutput: "The red mug is on the left side of the desk"\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Considerations"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Latency: 1-10 seconds typical"}),"\n",(0,s.jsx)(n.li,{children:"Hallucination: May describe objects that don't exist"}),"\n",(0,s.jsx)(n.li,{children:"Resolution: Image may be downsampled internally"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"latency",children:"Latency Expectations"}),"\n",(0,s.jsx)(n.h3,{id:"typical-inference-times",children:"Typical Inference Times"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Component"}),(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Typical Latency"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Speech (Whisper)"}),(0,s.jsx)(n.td,{children:"base"}),(0,s.jsx)(n.td,{children:"100-200ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Speech (Whisper)"}),(0,s.jsx)(n.td,{children:"small"}),(0,s.jsx)(n.td,{children:"250-500ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"LLM (GPT-4)"}),(0,s.jsx)(n.td,{children:"API"}),(0,s.jsx)(n.td,{children:"500-2000ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"LLM (local 7B)"}),(0,s.jsx)(n.td,{children:"GPU"}),(0,s.jsx)(n.td,{children:"200-500ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"VLM (LLaVA)"}),(0,s.jsx)(n.td,{children:"7B, GPU"}),(0,s.jsx)(n.td,{children:"1000-3000ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"VLM (GPT-4V)"}),(0,s.jsx)(n.td,{children:"API"}),(0,s.jsx)(n.td,{children:"2000-5000ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Embedding"}),(0,s.jsx)(n.td,{children:"text"}),(0,s.jsx)(n.td,{children:"10-50ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Object Detection"}),(0,s.jsx)(n.td,{children:"YOLOv8"}),(0,s.jsx)(n.td,{children:"10-30ms"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"budget-allocation-for-vla",children:"Budget Allocation for VLA"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Voice command to robot action:\r\n\u251c\u2500\u2500 Speech capture: 2000ms (user speaking)\r\n\u251c\u2500\u2500 Whisper: 200ms\r\n\u251c\u2500\u2500 LLM planning: 500ms\r\n\u251c\u2500\u2500 VLM (if needed): 2000ms\r\n\u251c\u2500\u2500 Grounding: 50ms\r\n\u251c\u2500\u2500 Safety check: 10ms\r\n\u2514\u2500\u2500 Total: ~2760ms (without VLM) or ~4760ms (with VLM)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"failures",children:"Common Failure Modes"}),"\n",(0,s.jsx)(n.h3,{id:"hallucination",children:"Hallucination"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What"}),": Model generates plausible but incorrect information."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'VLM: "I see three mugs on the table"\r\nReality: Only two mugs present\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mitigation"}),": Cross-check with object detection; don't trust counts."]}),"\n",(0,s.jsx)(n.h3,{id:"out-of-distribution",children:"Out-of-Distribution"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What"}),": Input differs from training data."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Trained on: Indoor office environments\r\nDeployed in: Industrial warehouse\r\nResult: Poor object recognition\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mitigation"}),": Test on target environment; use domain randomization."]}),"\n",(0,s.jsx)(n.h3,{id:"context-length-overflow",children:"Context Length Overflow"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What"}),": Input exceeds model's maximum context."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Long conversation + large image + detailed prompt = truncation\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mitigation"}),": Summarize history; limit prompt size."]}),"\n",(0,s.jsx)(n.h3,{id:"latency-spike",children:"Latency Spike"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What"}),": Unexpectedly slow inference."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Example"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Normal: 500ms\r\nSpike: 5000ms (due to API throttling or GPU contention)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mitigation"}),": Set timeouts; implement fallbacks."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"guidelines",children:"Practical Guidelines"}),"\n",(0,s.jsx)(n.h3,{id:"when-to-use-neural-networks",children:"When to Use Neural Networks"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Good Fit"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Pattern recognition (objects, speech, faces)"}),"\n",(0,s.jsx)(n.li,{children:"Semantic understanding (language, scenes)"}),"\n",(0,s.jsx)(n.li,{children:"Complex mappings difficult to hand-code"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Poor Fit"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Safety-critical decisions (use traditional verification)"}),"\n",(0,s.jsx)(n.li,{children:"Precise numeric computation (use explicit calculation)"}),"\n",(0,s.jsx)(n.li,{children:"Real-time control loops (latency may be too high)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"integration-best-practices",children:"Integration Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validate outputs"}),": Never trust neural network output for safety"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Set timeouts"}),": Handle slow/failed inference gracefully"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Log everything"}),": Record inputs and outputs for debugging"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Test boundaries"}),": Identify where models fail"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cache when possible"}),": Repeated queries \u2192 cached results"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"questions-to-ask-before-using-a-model",children:"Questions to Ask Before Using a Model"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Question"}),(0,s.jsx)(n.th,{children:"Why It Matters"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What was it trained on?"}),(0,s.jsx)(n.td,{children:"Predicts where it will work"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What's the latency?"}),(0,s.jsx)(n.td,{children:"Fits your timing budget?"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What's the failure mode?"}),(0,s.jsx)(n.td,{children:"How to handle errors?"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What hardware does it need?"}),(0,s.jsx)(n.td,{children:"GPU requirements"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"What's the cost?"}),(0,s.jsx)(n.td,{children:"API fees, compute costs"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"For effective use of ML in robotics, understand:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Neural networks"})," approximate functions from data\u2014they may fail on unfamiliar inputs."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Embeddings"})," represent meaning as numbers\u2014enabling semantic similarity search."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Transformers"})," use attention to process context\u2014enabling language and vision understanding."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Latency varies significantly"}),"\u2014budget time carefully in VLA pipelines."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Failure modes are predictable"}),"\u2014design systems to handle hallucination, timeouts, and out-of-distribution inputs."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You don't need to train these models\u2014but you do need to understand their capabilities and limitations to use them safely and effectively in robotic systems."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453(e,n,i){i.d(n,{R:()=>l,x:()=>d});var t=i(6540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);